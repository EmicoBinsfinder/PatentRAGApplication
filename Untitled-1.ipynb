{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "import pytesseract\n",
    "import os\n",
    "import base64\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "import uuid\n",
    "import chromadb\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.schema.document import Document\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "import openai\n",
    "import gradio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eeo21\\Anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# API Key\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = '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'\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "openai.api_key = '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'\n",
    "\n",
    "# OpenAI Model\n",
    "\n",
    "chain_gpt_35 = ChatOpenAI(model=\"gpt-4-0125-preview\", max_tokens=1024, api_key=OPENAI_API_KEY)\n",
    "chain_gpt_4_vision = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=1024, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eeo21\\Anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Initialize the retriever\n",
    "vectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings())\n",
    "retriever = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=id_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add documents to the retriever\n",
    "def add_documents_to_retriever(summaries, original_contents):\n",
    "    id_key = \"doc_id\"\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in summaries]\n",
    "    summary_docs = [\n",
    "        Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "        for i, s in enumerate(summaries)\n",
    "    ]\n",
    "    retriever.vectorstore.add_documents(summary_docs)\n",
    "    retriever.docstore.mset(list(zip(doc_ids, original_contents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('your-current-account-terms.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "summaries = (list(data.keys()))\n",
    "elements = (list(data.values()))\n",
    "\n",
    "add_documents_to_retriever(summaries, elements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define prompt template\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context, which can include text, images and tables:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "Aim = 'Quality' #Change to slow for faster response, perhaps with lower quality\n",
    "\n",
    "if Aim == 'Quality':\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\")\n",
    "elif Aim == 'Fast':\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(f'{input}')\n",
    "contextlist = retriever.get_relevant_documents(f'{input}')\n",
    "print(contextlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eeo21\\Anaconda3\\lib\\site-packages\\gradio\\blocks.py:530: UserWarning: Cannot load compact. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/compact (Request ID: Root=1-65fc29bd-4f16b2dd4ca38b151beda7cd;e820f2cb-2dae-4420-806b-194c4d2659f0)\n",
      "\n",
      "Sorry, we can't find the page you are looking for.\n",
      "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chatbot(input):\n",
    "    response = chain.invoke(f'{input}')\n",
    "\n",
    "    # contextlist = retriever.get_relevant_documents(f'{input}')\n",
    "\n",
    "    # #Remove any duplicated contexts\n",
    "    # print(contextlist)\n",
    "\n",
    "    #Get ID of patent that context was retreived from \n",
    "    # for x in contextlist:\n",
    "    #     comps = x.split('###_###')\n",
    "    #     context = comps[0]\n",
    "    #     ID = comps[1]\n",
    "\n",
    "    # # Prettify response\n",
    "    # response = response.replace('**', '')\n",
    "    # response = '\\n'.join([response, f\"{'#'*120} \\n\"])\n",
    "    # response = '\\n'.join([response, f\"CONTEXT USED TO GENERATE RESPONSE:\\n {context}\"])\n",
    "    # response = '\\n'.join([response, f\"{'#'*120} \\n\"])\n",
    "    # response = '\\n'.join([response, f\"CONTEXT FOUND IN PATENT NO. {ID}\"])\n",
    "   \n",
    "    return response\n",
    "\n",
    "inputs = gradio.Textbox(lines=7, label=\"Ask question based on facts from NatWest's Customer Service Page\")\n",
    "outputs = gradio.Textbox(label=\"Reply\")\n",
    "\n",
    "gradio.Interface(fn=chatbot, inputs=inputs, outputs=outputs, title=\"KIA Bank Chatbot Prototype\",\n",
    "             theme=\"compact\").launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
